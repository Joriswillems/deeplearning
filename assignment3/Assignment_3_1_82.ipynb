{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment-3.1_82.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joriswillems/deeplearning/blob/master/assignment3/Assignment_3_1_82.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5BoXrK_u3u_"
      },
      "source": [
        "# Assignment 3.1. Sequence Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sr9zwNA-u3vH"
      },
      "source": [
        "# Task: Aspect-level Sentiment Classification(10pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y506kXSAu3vP"
      },
      "source": [
        "<b>Group 82</b>\n",
        "* <b> Student 1 </b> : Joris Willems + 0908753\n",
        "* <b> Student 2 </b> : Lars Schilders + 0908729\n",
        "\n",
        "Reading material:\n",
        "- [1] R. He, WS. Lee & D. Dahlmeier. Exploiting document knowledge for aspect-level sentiment classification. 2018. https://arxiv.org/abs/1806.04346.\n",
        "\n",
        "\n",
        "Build an attention-based aspect-level sentiment classification model with biLSTM. Your model shall include:\n",
        "\n",
        "- BiLSTM network that learns sentence representation from input sequences.\n",
        "- Attention network that assigns attention score over a sequence of biLSTM hidden states based on aspect terms representation.\n",
        "- Fully connected network that predicts sentiment label, given the representation weighted by the attention score.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "- You shall train your model bsaed on transferring learning. That is, you need first train your model on documnet-level examples. Then the learned weights will be used to initialize aspect-level model and fine tune it on aspect-level examples.\n",
        "- You shall use the alignment score function in attention network as following expression:$$f_{score}(h,t)=tanh(h^TW_a t)$$\n",
        "- You shall evaluate the trained model on the provided test set and show the accuracy on test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FB6yxc4BM9uU",
        "outputId": "91bda410-d2f7-475b-ed38-6305df466015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BPDMoaQNNAC5",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import codecs\n",
        "import operator\n",
        "import numpy as np\n",
        "import re\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ymEccUbRNEGd",
        "colab": {}
      },
      "source": [
        "import _pickle as cPickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k9TH6Um2s-7d"
      },
      "source": [
        "\n",
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LbWy_h2KtNgR",
        "colab": {}
      },
      "source": [
        "def read_pickle(data_path, file_name):\n",
        "\n",
        "    f = open(os.path.join(data_path, file_name), 'rb')\n",
        "    read_file = cPickle.load(f)\n",
        "    f.close()\n",
        "\n",
        "    return read_file\n",
        "\n",
        "def save_pickle(data_path, file_name, data):\n",
        "\n",
        "    f = open(os.path.join(data_path, file_name), 'wb')\n",
        "    cPickle.dump(data, f)\n",
        "    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n",
        "    f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fuAMxdYBkv_x",
        "colab": {}
      },
      "source": [
        "aspect_path = '/drive/My Drive/Colab Notebooks/2IMM10 - Deep Learning/Assignment 3/aspect-level' \n",
        "# aspect_path = '/content/drive/My Drive/deeplearning/data/aspect-level/'\n",
        "# aspect_path = '../courseFiles/Practicals/Practical 5/data/aspect-level/'\n",
        "\n",
        "vocab = read_pickle(aspect_path, 'all_vocab.pkl')\n",
        "\n",
        "train_x = read_pickle(aspect_path, 'train_x.pkl')\n",
        "train_y = read_pickle(aspect_path, 'train_y.pkl')\n",
        "dev_x = read_pickle(aspect_path, 'dev_x.pkl')\n",
        "dev_y = read_pickle(aspect_path, 'dev_y.pkl')\n",
        "test_x = read_pickle(aspect_path, 'test_x.pkl')\n",
        "test_y = read_pickle(aspect_path, 'test_y.pkl')\n",
        "\n",
        "train_aspect = read_pickle(aspect_path, 'train_aspect.pkl')\n",
        "dev_aspect = read_pickle(aspect_path, 'dev_aspect.pkl')\n",
        "test_aspect = read_pickle(aspect_path, 'test_aspect.pkl')\n",
        "\n",
        "\n",
        "pretrain_data = read_pickle(aspect_path, 'pretrain_data.pkl')\n",
        "pretrain_label = read_pickle(aspect_path, 'pretrain_label.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD4SZS9gWGGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DecodeSequence(idx):\n",
        "    review = str([list(vocab.keys())[i] for i in train_x[idx] if i!=0])\n",
        "    aspectTerm = [list(vocab.keys())[i] for i in train_aspect[idx]]\n",
        "    target = [\"Positive\", \"Negative\", \"Neutral\"][int(np.nonzero(train_y[idx])[0])] \n",
        "    print(\"Full review: {}\".format(review))\n",
        "    print(\"Aspect terms: {}\".format(aspectTerm))\n",
        "    print(\"Target: {}\".format(target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rWVgGO8RlVIJ",
        "colab": {}
      },
      "source": [
        "class Dataiterator_doc():\n",
        "    '''\n",
        "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
        "      2) Access to the entire dataset using all()\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, X, y, seq_length=32, decoder_dim=300, batch_size=32):      \n",
        "        self.X = X \n",
        "        self.y = y \n",
        "        self.num_data = len(X) # total number of examples\n",
        "        self.batch_size = batch_size # batch size\n",
        "        self.reset() # initial: shuffling examples and set index to 0\n",
        "    \n",
        "    def __iter__(self): # iterates data\n",
        "        return self\n",
        "\n",
        "\n",
        "    def reset(self): # initials\n",
        "        self.idx = 0\n",
        "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
        "        \n",
        "    def __next__(self): # return model inputs - outputs per batch\n",
        "        X_ids = [] # hold ids per batch \n",
        "        while len(X_ids) < self.batch_size:\n",
        "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
        "            X_ids.append(X_id)\n",
        "            self.idx += 1 # \n",
        "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
        "                self.reset()\n",
        "                raise StopIteration()\n",
        "                \n",
        "        batch_X = self.X[np.array(X_ids)] # X values (encoder input) per batch\n",
        "        batch_y = self.y[np.array(X_ids)] # y_in values (decoder input) per batch\n",
        "        return batch_X, batch_y\n",
        "\n",
        "          \n",
        "    def all(self): # return all data examples\n",
        "        return self.X, self.y\n",
        "class Dataiterator_aspect():\n",
        "    '''\n",
        "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
        "      2) Access to the entire dataset using all()\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, aspect_data, seq_length=32, decoder_dim=300, batch_size=32):\n",
        "        \n",
        "        len_aspect_data = len(aspect_data[0])\n",
        "        #self.len_doc_data = len(doc_data[0])\n",
        "        \n",
        "        self.X_aspect = aspect_data[0] \n",
        "        self.y_aspect = aspect_data[1]\n",
        "        self.aspect_terms = aspect_data[2]  \n",
        "        self.num_data = len_aspect_data\n",
        "        self.batch_size = batch_size # batch size\n",
        "        self.reset() # initial: shuffling examples and set index to 0\n",
        "    \n",
        "    def __iter__(self): # iterates data\n",
        "        return self\n",
        "\n",
        "\n",
        "    def reset(self): # initials\n",
        "        self.idx = 0\n",
        "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
        "        \n",
        "    def __next__(self): # return model inputs - outputs per batch\n",
        "        \n",
        "        X_ids = [] # hold ids per batch \n",
        "        while len(X_ids) < self.batch_size:\n",
        "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
        "            X_ids.append(X_id)\n",
        "            self.idx += 1 # \n",
        "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
        "                self.reset()\n",
        "                raise StopIteration()\n",
        "                \n",
        "        batch_X_aspect = self.X_aspect[np.array(X_ids)] # X values (encoder input) per batch\n",
        "        batch_y_aspect = self.y_aspect[np.array(X_ids)] # y_in values (decoder input) per batch\n",
        "        batch_aspect_terms = self.aspect_terms[np.array(X_ids)]\n",
        "        \n",
        "        return batch_X_aspect, batch_y_aspect, batch_aspect_terms\n",
        "\n",
        "          \n",
        "    def all(self): # return all data examples\n",
        "        return self.X_aspect, self.y_aspect, self.aspect_terms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "38IEEx0du3vW",
        "outputId": "a0e43f00-366f-4185-a8c8-2d495d97d29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Dense, Lambda, Dropout, LSTM,Bidirectional\n",
        "from keras.layers import Reshape, Activation, RepeatVector, concatenate, Concatenate, Dot, Multiply, Add\n",
        "import keras.backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cduHSpsSnVue",
        "colab": {}
      },
      "source": [
        "overal_maxlen = 82\n",
        "overal_maxlen_aspect = 7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bhTQke3HnvHN"
      },
      "source": [
        "\n",
        "# Define Attention Network Layer\n",
        "- Define class for Attention Layer\n",
        "- You need to finish the code for calculating the attention weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J2iL2CHWGGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cnDX-po3_50B",
        "colab": {}
      },
      "source": [
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self,  **kwargs):\n",
        "        \"\"\"\n",
        "        Keras Layer that implements an Content Attention mechanism.\n",
        "        Supports Masking.\n",
        "        \"\"\"\n",
        "       \n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert type(input_shape) == list\n",
        "       \n",
        "        self.steps = input_shape[0][1]\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[0][-1], input_shape[1][-1]),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input_tensor, mask=None):\n",
        "        assert type(input_tensor) == list\n",
        "        assert type(mask) == list\n",
        "        return None\n",
        "\n",
        "    def call(self, input_tensor, mask=None):\n",
        "        \n",
        "        # output of BiLSTM for sentence (h in paper)\n",
        "        x = input_tensor[0]  #(None, 82, 600)\n",
        "        \n",
        "        # output of word embedding layer of aspect terms (t in paper)\n",
        "        aspect = input_tensor[1] #(None, 300)\n",
        "        \n",
        "        # used to remove influence of padded value\n",
        "        #mask = mask[0]\n",
        "        \n",
        "        #(None, 600)\n",
        "        aspect = K.transpose(K.dot(self.W, K.transpose(aspect)))\n",
        "        \n",
        "        #(None, 1, 600)\n",
        "        aspect = K.expand_dims(aspect, axis=-2)\n",
        "        \n",
        "        #(None, 82, 600)\n",
        "        aspect = K.repeat_elements(aspect, self.steps, axis=1)\n",
        "        \n",
        "        #(None, 82)\n",
        "        beta_vec = K.tanh(K.sum(x*aspect, axis=-1))\n",
        "        \n",
        "        #(None, 82)\n",
        "        alpha = K.exp(beta_vec)\n",
        "        alpha /= K.cast(K.sum(alpha, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        \n",
        "        return alpha\n",
        "    \n",
        "   \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        print((input_shape[0][0], input_shape[0][1]))\n",
        "        return (input_shape[0][0], input_shape[0][1]) #(None, 82)\n",
        "\n",
        "\n",
        "    ##### van paper ######\n",
        "    def call2(self, input_tensor, mask=None):\n",
        "        x = input_tensor[0]\n",
        "        aspect = input_tensor[1]\n",
        "        mask = mask[0]\n",
        "\n",
        "        aspect = K.transpose(K.dot(self.W, K.transpose(aspect)))\n",
        "        aspect = K.expand_dims(aspect, axis=-2)\n",
        "        aspect = K.repeat_elements(aspect, self.steps, axis=1)\n",
        "        eij = K.sum(x*aspect, axis=-1)\n",
        "\n",
        "        if self.bias:\n",
        "            b = K.repeat_elements(self.b, self.steps, axis=0)\n",
        "            eij += b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        return a\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V5PSPx85EiVn",
        "colab": {}
      },
      "source": [
        "class Average(Layer):\n",
        "  \n",
        "    def __init__(self, mask_zero=True, **kwargs):\n",
        "        self.mask_zero = mask_zero\n",
        "        self.supports_masking = True\n",
        "        super(Average, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x,mask=None):\n",
        "        if self.mask_zero:           \n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            mask = K.expand_dims(mask)\n",
        "            x = x * mask\n",
        "            return K.sum(x, axis=1) / (K.sum(mask, axis=1) + K.epsilon())\n",
        "        else:\n",
        "            return K.mean(x, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[-1])\n",
        "    \n",
        "    def compute_mask(self, x, mask):\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GsZtx2PbEqoh"
      },
      "source": [
        "# Establish computation Grah for model\n",
        "- Input tensors\n",
        "- Shared WordEmbedding layer \n",
        "- Attention network layer  \n",
        "- Shared BiLSTM layer\n",
        "- Shared fully connected layer(prediction layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xe55OCNZEmYY",
        "colab": {}
      },
      "source": [
        "dropout = 0.5     \n",
        "recurrent_dropout = 0.1\n",
        "vocab_size = len(vocab)\n",
        "num_outputs = 3 # labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2BpzACdBp3xG"
      },
      "source": [
        "## Input tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaNsr7ORWGGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pretrain data: document-level input (30000,300), output (30000,3)\n",
        "#[train_x, aspect_train]: aspect_level input (n_samples, 82) en (n_samples,7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KOi3CcOxE1MG",
        "outputId": "f2ae5655-98c7-432f-cc69-f0b4d357883e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#YOUR CODE HERE ##### Inputs #####\n",
        "sentence_input = Input(shape=(overal_maxlen,), dtype='int32', name='sentence_input')\n",
        "aspect_input = Input(shape=(overal_maxlen_aspect,), dtype='int32', name='aspect_input')\n",
        "pretrain_input = Input(shape=(None,), dtype='int32', name='pretrain_input')\n",
        "\n",
        "\n",
        "print(sentence_input)\n",
        "print(aspect_input)\n",
        "print(pretrain_input)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"sentence_input:0\", shape=(None, 82), dtype=int32)\n",
            "Tensor(\"aspect_input:0\", shape=(None, 7), dtype=int32)\n",
            "Tensor(\"pretrain_input:0\", shape=(None, None), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_vQ0z8KmrL3_"
      },
      "source": [
        "## Shared WordEmbedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GFEhEt9EE4Sn",
        "outputId": "f9b8cbb2-2323-417b-d97b-8e3157adb9d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#YOUR CODE HERE### represent aspect as averaged word embedding ###\n",
        "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')\n",
        "aspect_term_embs = word_emb(aspect_input)\n",
        "aspect_embs = Average(mask_zero=True, name='aspect_emb')(aspect_term_embs)\n",
        "\n",
        "print(aspect_term_embs)\n",
        "print(aspect_embs)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"word_emb/embedding_lookup/Identity_1:0\", shape=(None, 7, 300), dtype=float32)\n",
            "Tensor(\"aspect_emb/truediv:0\", shape=(None, 300), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8gGd94OGE-Gr",
        "outputId": "3e801d11-e798-46c9-91b1-40390c2fb169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#YOUR CODE HERE ### sentence representation from embedding ###\n",
        "sentence_embs = word_emb(sentence_input) # from aspect-level domain\n",
        "pretrain_embs = word_emb(pretrain_input) # from document-level domain\n",
        "\n",
        "print(sentence_embs)\n",
        "print(pretrain_embs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"word_emb_1/embedding_lookup/Identity_1:0\", shape=(None, 82, 300), dtype=float32)\n",
            "Tensor(\"word_emb_2/embedding_lookup/Identity_1:0\", shape=(None, None, 300), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pmcnAQufrc7o"
      },
      "source": [
        "## Shared BiLSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bm_yCjX_F7ml",
        "outputId": "ae3487b4-5f39-4b35-9179-b0a651357c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#YOUR CODE HERE ### sentence representation from embedding ###\n",
        "bilstm = Bidirectional(LSTM(300, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout), name='BiLSTM')\n",
        "pretrain_lstm = bilstm(pretrain_embs) #pretrain the bilstm (no attention involved) MUST BE AVERAGED\n",
        "sentence_lstm = bilstm(sentence_embs) #finetune bilstm with attention mechanism to obtain aspect-level info\n",
        "\n",
        "sentence_lstm"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'BiLSTM_1/concat:0' shape=(None, 82, 600) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIk6s-2mWGG0",
        "colab_type": "code",
        "outputId": "95842eca-6a0b-4e35-8752-ce30060f217b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pretrain_lstm"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'BiLSTM/concat:0' shape=(None, None, 600) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "99ZNrbkmrllN"
      },
      "source": [
        "## Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HO5Pj6QANz7U",
        "outputId": "38ae7176-32d0-45f6-9f20-8b8179e024b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "##YOUR CODE HERE\n",
        "attention = Attention()([sentence_lstm, aspect_embs])\n",
        "attention"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 82)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'attention_1/truediv:0' shape=(None, 82) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5-LY6jF8r3mO"
      },
      "source": [
        "## Prediction Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM7CExMjWGG7",
        "colab_type": "code",
        "outputId": "2d181945-76e1-4376-9f50-fc8f7e69f8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = Dot(axes=1)([sentence_lstm, attention])\n",
        "\n",
        "predictionLayer = Dense(3, activation='softmax')\n",
        "\n",
        "aspect_probs = predictionLayer(z)\n",
        "\n",
        "pretrain_avg = Average(mask_zero=True)(pretrain_lstm)\n",
        "pretrain_probs = predictionLayer(pretrain_avg)\n",
        "\n",
        "pretrain_probs"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense_1_1/Softmax:0' shape=(None, 3) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34RStEX4WGG-",
        "colab_type": "code",
        "outputId": "5783bf44-8b69-4d7b-f884-9d5501d3e04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "aspect_probs"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense_1/Softmax:0' shape=(None, 3) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0XLv1t9Ou3vx"
      },
      "source": [
        "# Build Models for document-level and aspect-level data\n",
        "- The two models shared the embedding, BiLSTM, Prediction Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RX8qKfNWu3v0",
        "outputId": "8523aa70-21f6-4908-83bc-fd27c5bcf14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "### YOUR CODE HERE\n",
        "model1 = Model(inputs=[pretrain_input], outputs=[pretrain_probs])\n",
        "\n",
        "model2 = Model(inputs=[sentence_input, aspect_input], outputs=[aspect_probs])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "sentence_input (InputLayer)     (None, 82)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "aspect_input (InputLayer)       (None, 7)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_emb (Embedding)            multiple             3000900     aspect_input[0][0]               \n",
            "                                                                 sentence_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "BiLSTM (Bidirectional)          multiple             1442400     word_emb[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "aspect_emb (Average)            (None, 300)          0           word_emb[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "attention_1 (Attention)         (None, 82)           180000      BiLSTM[1][0]                     \n",
            "                                                                 aspect_emb[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 600)          0           BiLSTM[1][0]                     \n",
            "                                                                 attention_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 3)            1803        dot_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 4,625,103\n",
            "Trainable params: 4,625,103\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FWqofwqBsgsn"
      },
      "source": [
        "# Train Model\n",
        "- First Train model on document-level data.\n",
        "- Then Train  model on aspect-level data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WSLYsZm7yPwi"
      },
      "source": [
        "## Train on document-level data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GHe86c6Yu3wG",
        "colab": {}
      },
      "source": [
        "\n",
        "import keras.optimizers as opt\n",
        "optimizer=opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)\n",
        "model1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "batch_size = 128\n",
        "train_steps_epoch = len(pretrain_data)/batch_size\n",
        "batch_train_iter_doc = Dataiterator_doc(pretrain_data, pretrain_label, batch_size=batch_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HfEvhdbhFlbR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "35a74c36-787b-44cd-c6b7-8a63f1ee3822"
      },
      "source": [
        "###YOUR CODE HERE###\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "history1 = model1.fit_generator(batch_train_iter_doc, \n",
        "                     steps_per_epoch=train_steps_epoch,\n",
        "                     epochs=20, \n",
        "                     )"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 67/234 [=======>......................] - ETA: 5:35 - loss: 0.7749 - categorical_accuracy: 0.6500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-1ab7c5b681f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m history = model1.fit_generator(batch_train_iter_doc, \n\u001b[1;32m      7\u001b[0m                      \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                      )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G-SYaHNMyXWX"
      },
      "source": [
        "## Train on aspect-level data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lCLGP6HTFsKL",
        "colab": {}
      },
      "source": [
        "train_steps_epoch = len(train_x)/batch_size\n",
        "batch_train_iter_aspect = Dataiterator_aspect([train_x, train_y, train_aspect], batch_size=batch_size)\n",
        "val_steps_epoch = len(dev_x)/batch_size\n",
        "batch_val_iter_aspect = Dataiterator_aspect([dev_x, dev_y, dev_aspect], batch_size=batch_size)\n",
        "\n",
        "import keras.optimizers as opt\n",
        "optimizer = opt.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clipnorm=10, clipvalue=0)\n",
        "model2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kvT2GqG0LONz",
        "outputId": "1fb144ad-956b-4d4a-8b64-4169a688a111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "def train_gen_aspect():\n",
        "    while True:\n",
        "        train_batches = [[[X, aspect], [y]] for X, y, aspect in batch_train_iter_aspect]\n",
        "        \n",
        "        for batch in train_batches:\n",
        "            yield batch\n",
        "            \n",
        "def val_gen_aspect():\n",
        "    while True:\n",
        "        val_batches = [[[X, aspect], [y]] for X, y, aspect in batch_val_iter_aspect]\n",
        "        \n",
        "        for batch in val_batches:\n",
        "            yield batch\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=2)\n",
        "  \n",
        "history2 = model2.fit_generator(train_gen_aspect(), \n",
        "                     steps_per_epoch=train_steps_epoch, \n",
        "                     epochs=10,\n",
        "                     validation_data=val_gen_aspect(),\n",
        "                     validation_steps=val_steps_epoch,\n",
        "                     callbacks=[es]\n",
        "                     )"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "15/14 [===============================] - 12s 795ms/step - loss: 0.8999 - categorical_accuracy: 0.5844 - val_loss: 0.9135 - val_categorical_accuracy: 0.5918\n",
            "Epoch 2/10\n",
            "15/14 [===============================] - 10s 692ms/step - loss: 0.8342 - categorical_accuracy: 0.6245 - val_loss: 0.8012 - val_categorical_accuracy: 0.6172\n",
            "Epoch 3/10\n",
            "15/14 [===============================] - 10s 698ms/step - loss: 0.8182 - categorical_accuracy: 0.6438 - val_loss: 0.8430 - val_categorical_accuracy: 0.6562\n",
            "Epoch 4/10\n",
            "15/14 [===============================] - 11s 704ms/step - loss: 0.7897 - categorical_accuracy: 0.6724 - val_loss: 0.8374 - val_categorical_accuracy: 0.6523\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f403b420160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZVPNUQcuyAU3"
      },
      "source": [
        "## Evaluating on test set\n",
        "- show the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J_JQwuUHMisH",
        "colab": {}
      },
      "source": [
        "##YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lgZAtHE6xqhH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4d5ad204-be47-4b8c-b6d3-200bcf81f1af"
      },
      "source": [
        "loss, accuracy = model2.evaluate([test_x, test_aspect], test_y)\n",
        "\n",
        "print(\"Categorical accuracy: {:.3f}%\".format(accuracy*100))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "638/638 [==============================] - 2s 3ms/step\n",
            "Categorical accuracy: 57.994%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7CZkREsdXnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}